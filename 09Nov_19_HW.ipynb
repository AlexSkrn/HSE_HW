{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "у нас есть текст, которых лежит в файле city_smells.txt. Давайте проведем с ним элементарные количественные исследования:\n",
    "можно, например, узнать, сколько в тексте уникальных слов, размер самого длинного предложения и тд. Чтобы работать с текстом, который лежит в\n",
    "файле, нам надо:\n",
    "\n",
    "1. Открыть файл (не забудьте о режиме открытия и энкодинге) \n",
    "2. Прочитать его \n",
    "3. Сохранить текст в переменную, с которой можно работать дальше\n",
    "\n",
    "Предобработка текста: удалить пунктуацию, свести текст к нижнему регистру\n",
    "\n",
    "Что можно сделать с текстом: (пункты на выбор, минимум один)\n",
    "\n",
    "  1. определить среднюю длину слова в тексте\n",
    "  2. определить среднюю длину предложения в тексте\n",
    "  3. посчитать, во сколько раз самое длинное предложение длиннее самого короткого (такое же можно сделать со словами)\n",
    "  4. (не убирая пунктуацию) - среднее количество пунктуационных знаков в предложении\n",
    "  5. количество уникальных слов и пророрция общему количеству слов в тексте\n",
    "  6. что-то еще, что Вы сами захотите поисследовать\n",
    "\n",
    "Запишите результат Вашего мини-исследования в новый файл, добавьте его и (отдельный) файл с кодом в Ваш репозиторий.\n",
    "\n",
    "Удачи! \n",
    "Дедлайн - суббота, 16 ноября. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл для записи всех результатов\n",
    "output = open('city_smells_stats.txt', 'a', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('1. определить среднюю длину слова в тексте\\n', file=output)\n",
    "\n",
    "with open('city_smells.txt', 'r', encoding='utf-8') as f:\n",
    "    sent_list = [l for l in f if l != '\\n'] \n",
    "    \n",
    "print('Первые 3 предложения до обработки:\\n', file=output)\n",
    "print(sent_list[:3], file=output)\n",
    "\n",
    "norm_sent_list = []  # Lowercase and remove punctuation and numbers\n",
    "for seg in sent_list:\n",
    "    norm_sent_list.append(\"\".join((char.lower() if char.isalpha() else \" \") for char in seg).split())\n",
    "print('\\nПервые 3 предложения после обработки:\\n', file=output)\n",
    "print(norm_sent_list[:3], file=output)\n",
    "\n",
    "words_set = set()  # Count unique words\n",
    "for sent in norm_sent_list:\n",
    "    words_set.update(set([word for word in sent]))\n",
    "\n",
    "words_length_sum = sum([len(w) for w in words_set])  # Count the sum of word lengths\n",
    "print('\\nСредняя длина слова (сумма длин уник. слов / кол-во уник. слов): {} / {} = {}'\n",
    "      .format(words_length_sum, len(words_set), words_length_sum / len(words_set)),\n",
    "     file=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n5. количество уникальных слов и пророрция общему количеству слов в тексте\\n', file=output)\n",
    "import re\n",
    "\n",
    "with open('city_smells.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "words_num = re.findall('\\w+', txt.lower())  # Lowercase and remove punctuation \n",
    "words = [w for w in words_num if w.isalpha()]  # Get rid of numbers\n",
    "\n",
    "voc_size = len(set(words))\n",
    "ttl_words = len(words)\n",
    "str_form = 'Уникальных слов: {}\\nОбщее кол-во слов: {}\\nЛексическое разнообразие: {:.4f}'\n",
    "print(str_form.format(voc_size, ttl_words, voc_size / ttl_words), file=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\n6. что-то еще, что Вы сами захотите поисследовать\\n', file=output)\n",
    "\n",
    "# Топ-10 слов\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "with open('city_smells.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read()\n",
    "    \n",
    "words_num = re.findall('\\w+', txt.lower())  # Lowercase and remove punctuation\n",
    "words = [w for w in words_num if w.isalpha()]  # Get rid of numbers\n",
    "print('Топ-10 слов', file=output)\n",
    "print('Слово | Частота в тексте', file=output)\n",
    "print(Counter(words).most_common(10), file=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
